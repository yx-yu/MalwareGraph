import torch
import os
import math
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.dataset import ConcatDataset
from torch import optim
from torch.nn import functional as F
from torch.utils.data import Dataset, DataLoader
import torch.optim.lr_scheduler as lr_scheduler
import pandas as pd
from MCNN import MultiScaleCNN
from Mal_ViT import vit_malware as create_model
from sppnet import SPP_NET
from Mydataset import CustomDataset, BatchSchedulerSampler
from torchvision.datasets import DatasetFolder
import torchvision
from PIL import Image
from torchvision import transforms
from utils import read_split_data, plot_data_loader_image, read_data, calculate_metrics
import os
import torch
import argparse
from torchinfo import summary
# 并行训练
# import torch.distributed as dist
import torch.nn as nn
from datetime import timedelta
import torch.multiprocessing as mp
from torch.utils.data.distributed import DistributedSampler
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.distributed import init_process_group, destroy_process_group
import numpy as np
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import tsne
import joblib
from transformers import get_linear_schedule_with_warmup
import pickle

class Trainer:
    def __init__(self,
                 model1: torch.nn.Module,
                 model2: torch.nn.Module,
                 train_dataloader: DataLoader,
                 val_data_loader: DataLoader,
                 optimizer1: torch.optim.Optimizer,
                 optimizer2: torch.optim.Optimizer,
                 scheduler,
                 device,
                 batch_size
                 ) -> None:
        # rank
        self.device = device
        self.model1 = model1.to(device[0])
        self.model2 = model2.to(device[0])
        self.train_dataloader = train_dataloader
        self.val_data_loader = val_data_loader
        self.optimizer1 = optimizer1
        self.optimizer2 = optimizer2
        self.scheduler = scheduler
        self.batch_size = batch_size

    def _run_batch(self, xs, ys, running_loss):
        output1 = self.model1(xs.to(self.device[0]))
        loss1 = F.cross_entropy(output1, ys.to(self.device[0]))

        output2 = self.model2(xs.to(self.device[0]))
        loss2 = F.cross_entropy(output2, ys.to(self.device[0]))
        print(
            f"Training Loss1: {loss1:.4f}， Training Loss2: {loss2:.4f}")
        loss = loss1.to('cpu') + loss2.to('cpu')
        loss1.backward()
        loss2.backward()
        self.optimizer1.step()
        self.optimizer1.zero_grad()

        self.optimizer2.step()
        self.optimizer2.zero_grad()
        self.scheduler.step()  # 对学习率进行调整(会根据预先设定的学习率调整策略，动态地调整学习率的大小，以提高训练效果)
        running_loss += loss2.item() * xs.size(0)
        return running_loss

    def _run_epoch(self, epoch):
        running_loss = 0
        for xs, ys, padding in self.train_dataloader:
            xs = xs
            ys = ys
            running_loss = self._run_batch(xs, ys, running_loss)
            # self._evaluate_ada(args.num_classes)
            # metrics = self._evaluate_img(args.num_classes)
        return running_loss

    def train(self, max_epoch: int):
        for epoch in range(max_epoch):
            # 将模型设置为训练模式
            self.model1.train()
            self.model2.train()
            running_loss = self._run_epoch(epoch)
            epoch_loss = running_loss / len(self.train_dataloader.dataset)
            self._evaluate_ada(args.num_classes)
            metrics = self._evaluate_img(args.num_classes)
            print(f"Epoch {epoch + 1}: {metrics}")
            print(
                f"Epoch {epoch + 1} - Training Loss: {epoch_loss:.4f}")
            # 保存模型语句
            torch.save(self.model1.state_dict(), 'gg_model.pth')
            torch.save(self.model2.state_dict(), 'vit_malware.pth')

    def _evaluate_ada(self, num_classes):
        self.model1.eval()
        self.model2.eval()
        # 初始化混淆矩阵和样本数
        confusion_matrix = np.zeros((num_classes, num_classes))
        num_samples = 0
        plot_logits_list = []
        plot_label_list = []
        # 遍历数据集，计算混淆矩阵和样本数
        models = [self.model1, self.model2]

        # 初始化AdaBoost权重，初始时将所有样本权重设置为相等
        sample_weights = torch.ones(self.batch_size) / self.batch_size
        base_classifier = DecisionTreeClassifier(max_depth=1)
        adaboost_classifier = AdaBoostClassifier(
            base_classifier,
            n_estimators=50,
            learning_rate=1.0
        )
        # 设置AdaBoost迭代次数
        predictions = []
        for inputs, targets, padding in self.val_data_loader:
            # 将数据移动到设备上
            inputs = inputs
            targets = targets

            for num, model in enumerate(models):
                model.eval()  # 切换到评估模式
                with torch.no_grad():
                    outputs = model(inputs.to(self.device[num]))
                    predictions.append(outputs.cpu())
            # 计算每个模型的错误率
            predicted_labels = []
            for i in range(len(models)):
                _, predicted_label = torch.max(predictions[i], dim=1)
                predicted_labels.append(predicted_label.numpy())
            # 使用AdaBoost来融合两个模型的输出
            # 将两个模型的预测结果合并成一个特征矩阵
            ensemble_features = np.column_stack((predicted_labels[0], predicted_labels[1]))

            # 训练AdaBoost分类器
            adaboost_classifier.fit(ensemble_features, targets)

            # 使用AdaBoost分类器进行最终预测
            final_predictions = adaboost_classifier.predict(ensemble_features)

            # 计算集成模型的准确率
            accuracy = accuracy_score(targets, final_predictions)
            print(f"集成模型的准确率: {accuracy}")
        # 保存模型参数到文件
        joblib.dump(adaboost_classifier, 'adaboost_model.pkl')

    def _evaluate_img(self, num_classes):
        # self.model1.eval()
        self.model2.eval()
        # 从文件加载保存的模型参数
        loaded_adaboost_model = joblib.load('adaboost_model.pkl')
        # 初始化混淆矩阵和样本数
        confusion_matrix = np.zeros((num_classes, num_classes))
        num_samples = 0
        plot_logits_list = []
        plot_label_list = []
        # 遍历数据集，计算混淆矩阵和样本数
        with torch.no_grad():
            for inputs, targets, padding in self.val_data_loader:
                # 将数据移动到设备上
                inputs = inputs
                targets = targets
                # 前向传播，得到预测结果
                outputs1 = self.model1(inputs.to(self.device[0]))
                _, predicted1 = torch.max(outputs1, dim=1)
                outputs2 = self.model2(inputs.to(self.device[0]))
                _, predicted2 = torch.max(outputs2, dim=1)
                # 使用加载的模型进行预测
                ensemble_features = np.column_stack((predicted1.cpu(), predicted2.cpu()))
                predicted = loaded_adaboost_model.predict(ensemble_features)
                # 更新混淆矩阵和样本数
                for i in range(len(targets)):
                    confusion_matrix[targets[i], predicted[i]] += 1
                num_samples += len(targets)

                logits_np = outputs1.to('cpu').numpy()
                # softmax转换
                plot_logits_list.append(logits_np)
                plot_label_list.append(targets.to('cpu').numpy())
        # 计算指标

        # 指定保存pkl文件的路径和文件名
        file_path = 'my_array.pkl'

        # 使用pickle将ndarray保存到pkl文件中
        with open(file_path, 'wb') as file:
            pickle.dump(confusion_matrix, file)

        metrics0 = calculate_metrics(confusion_matrix)
        data = np.vstack(plot_logits_list)
        label = np.hstack(plot_label_list)
        tsne.t_sne(data, label)
        # CLASS = ['1', '2', '3', '4', '5', '6', '7', '8', '9']
        CLASS = ['0', '1', '2', '3', '4', '5', '6', '7', '8']
        NUM_CLASS = len(CLASS)
        metrics1 = classification_report(targets, predicted, target_names=CLASS, digits=4,
                                         labels=list(range(NUM_CLASS)), zero_division=1)
        tsne.plot_matrix(confusion_matrix, CLASS)
        print(metrics0, '============================================== /n', metrics1)
        # 返回结果
        return metrics0, metrics1

    def _evaluate_vote(self, num_classes):
        self.model1.eval()
        self.model2.eval()
        # 初始化混淆矩阵和样本数
        confusion_matrix = np.zeros((num_classes, num_classes))
        num_samples = 0
        plot_logits_list = []
        plot_label_list = []
        # 遍历数据集，计算混淆矩阵和样本数
        with torch.no_grad():
            for inputs, targets, padding in self.val_data_loader:
                # 将数据移动到设备上
                inputs = inputs
                targets = targets.to(self.device[0])

                # 前向传播，得到预测结果
                with torch.no_grad():
                    y_pred1 = self.model1(inputs.to(self.device[0]))
                    y_pred2 = self.model2(inputs.to(self.device[0]))
                y_pred1 = torch.argmax(y_pred1, dim=1).cpu().numpy()
                y_pred2 = torch.argmax(y_pred2, dim=1).cpu().numpy()
                predictions = [y_pred1, y_pred2]  # 存储每个模型的预测结果
                # 多数投票（majority voting）：对于每个样本，根据多数预测结果决定最终结果
                ensemble_predictions = torch.stack(predictions).mean(dim=0)  # 平均投票
                # 可以根据需要进行后处理，例如应用softmax来获得概率分布
                ensemble_predictions = F.softmax(ensemble_predictions, dim=1)
                _, predicted = torch.max(ensemble_predictions, dim=1)
                # 更新混淆矩阵和样本数
                for i in range(len(targets)):
                    confusion_matrix[targets[i], predicted[i]] += 1
                num_samples += len(targets)

                logits_np = ensemble_predictions.to('cpu').numpy()
                # softmax转换
                plot_logits_list.append(logits_np)
                plot_label_list.append(targets.to('cpu').numpy())
        # 计算指标
        metrics0 = calculate_metrics(confusion_matrix)
        data = np.vstack(plot_logits_list)
        label = np.hstack(plot_label_list)
        tsne.t_sne(data, label)
        CLASS = ['1', '2', '3', '4', '5', '6', '7', '8', '9']
        NUM_CLASS = len(CLASS)
        metrics1 = classification_report(targets.cpu(), predicted.cpu(), target_names=CLASS, digits=4,
                                         labels=list(range(NUM_CLASS)), zero_division=1)
        print(metrics0, '==============================================/n', metrics1)
        # 返回结果
        return metrics0


# 训练函数
# def train(model, dataloader, optimizer, criterion):
#     model.train()
#     running_loss = 0.0
#     for inputs, targets, padding in dataloader:
#         optimizer.zero_grad()
#         # 将数据移动到指定的设备
#         inputs = inputs.to(self.device)
#         targets = targets.to(self.device)
#         outputs = model(inputs)
#         loss = criterion(outputs, targets)
#         print(
#             f"Training Loss: {loss:.4f}")
#         loss.backward()
#         optimizer.step()
#         running_loss += loss.item() * inputs.size(0)
#     epoch_loss = running_loss / len(dataloader.dataset)
#     return epoch_loss


# 创建数据集和数据加载器
# 调用 BCDI/BIG/天融信数据集

# transforms.Normalize(normMean=[0.30137167], normStd=[0.30272897])  # train_dataset
data_transform = {
    "resize": transforms.Compose([transforms.Resize((256, 256)),
                                  transforms.ToTensor(),
                                  transforms.Normalize([0.30137167], [0.30272897])]),

    "un_resize": transforms.Compose([transforms.ToTensor(),
                                     transforms.Normalize([0.30137167], [0.30272897])])}


# data_transform = {
#     "train": transforms.Compose([transforms.RandomResizedCrop(224),
#                                  transforms.RandomHorizontalFlip(),
#                                  transforms.ToTensor(),
#                                  transforms.Normalize([0.30137167], [0.30272897])]),
#     "val": transforms.Compose([transforms.Resize(256),
#                                transforms.CenterCrop(224),
#                                transforms.ToTensor(),
#                                transforms.Normalize([0.30137167], [0.30272897])])}


def main(args):
    # # 将模型移动到指定的设备
    # # 计算global_rank和world_size
    # global_rank = local_rank + args.node_rank * args.nproc_per_node
    # world_size = args.nnode * args.nproc_per_node
    # 设置seed
    RANDOM_SEED = 1
    torch.manual_seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)
    # train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(root_dir)
    train_images_path_256, train_images_label_256, val_images_path_256, val_images_label_256 = read_data(args.root_dir,
                                                                                                         '256',
                                                                                                         val_rate=args.val_rate)
    train_images_path_512, train_images_label_512, val_images_path_512, val_images_label_512 = read_data(args.root_dir,
                                                                                                         '512',
                                                                                                         val_rate=args.val_rate)
    train_images_path_1024, train_images_label_1024, val_images_path_1024, val_images_label_1024 = read_data(
        args.root_dir,
        '1024',
        val_rate=args.val_rate)
    train_images_path_2048, train_images_label_2048, val_images_path_2048, val_images_label_2048 = read_data(
        args.root_dir,
        '2048',
        val_rate=args.val_rate)
    dataset_256 = CustomDataset(images_path=train_images_path_256,
                                images_class=train_images_label_256,
                                extensions=('.txt', '.jpg', '.png'),
                                transform=data_transform["un_resize"])
    dataset_512 = CustomDataset(images_path=train_images_path_512,
                                images_class=train_images_label_512,
                                extensions=('.txt', '.jpg', '.png'),
                                transform=data_transform["un_resize"])
    dataset_1024 = CustomDataset(images_path=train_images_path_1024,
                                 images_class=train_images_label_1024,
                                 extensions=('.txt', '.jpg', '.png'),
                                 transform=data_transform["un_resize"])
    dataset_2048 = CustomDataset(images_path=train_images_path_2048,
                                 images_class=train_images_label_2048,
                                 extensions=('.txt', '.jpg', '.png'),
                                 transform=data_transform["un_resize"])
    concat_dataset = ConcatDataset([dataset_256, dataset_512, dataset_1024, dataset_2048])
    # concat_dataset = ConcatDataset([dataset_512, dataset_1024, dataset_2048])

    nw = min([os.cpu_count(), args.batch_size if args.batch_size > 1 else 0, 8])  # number of workers
    print('Using {} dataloader workers'.format(nw))

    # train_dataloader = torch.utils.data.DataLoader(concat_dataset,
    #                                                batch_size=args.batch_size,
    #                                                sampler=BatchSchedulerSampler(dataset=concat_dataset,
    #                                                                              batch_size=args.batch_size),
    #                                                num_workers=4,
    #                                                shuffle=False,
    #                                                pin_memory=True,
    #                                                collate_fn=dataset_256.collate_fn)

    train_dataloader = torch.utils.data.DataLoader(concat_dataset,
                                                   batch_size=args.batch_size,
                                                   # batch input: split to each gpus (且没有任何 overlaping samples 各个 gpu 之间)
                                                   sampler=BatchSchedulerSampler(dataset=concat_dataset,
                                                                                 batch_size=args.batch_size),
                                                   num_workers=0,
                                                   shuffle=False,
                                                   pin_memory=True,
                                                   collate_fn=dataset_256.collate_fn)

    dataset_256_v = CustomDataset(images_path=val_images_path_256,
                                  images_class=val_images_label_256,
                                  extensions=('.txt', '.jpg', '.png'),
                                  transform=data_transform["un_resize"])
    dataset_512_v = CustomDataset(images_path=val_images_path_512,
                                  images_class=val_images_label_512,
                                  extensions=('.txt', '.jpg', '.png'),
                                  transform=data_transform["un_resize"])
    dataset_1024_v = CustomDataset(images_path=val_images_path_1024,
                                   images_class=val_images_label_1024,
                                   extensions=('.txt', '.jpg', '.png'),
                                   transform=data_transform["un_resize"])
    dataset_2048_v = CustomDataset(images_path=val_images_path_2048,
                                   images_class=val_images_label_2048,
                                   extensions=('.txt', '.jpg', '.png'),
                                   transform=data_transform["un_resize"])
    concat_dataset_v = ConcatDataset([dataset_256_v, dataset_512_v, dataset_1024_v, dataset_2048_v])

    nw = min([os.cpu_count(), args.batch_size if args.batch_size > 1 else 0, 8])  # number of workers

    val_data_loaderaloader = torch.utils.data.DataLoader(concat_dataset_v,
                                                         batch_size=args.batch_size,
                                                         # sampler=BatchSchedulerSampler(dataset=concat_dataset_v,
                                                         #                               batch_size=args.batch_size),
                                                         # batch input: split to each gpus (且没有任何 overlaping samples
                                                         # 各个 gpu 之间)
                                                         num_workers=0,
                                                         shuffle=False,
                                                         pin_memory=True,
                                                         collate_fn=dataset_512_v.collate_fn)
    # 创建模型1、优化器和损失函数
    model1 = SPP_NET(number_classes=args.num_classes)
    if args.continue_train:
        # saved_model_path = "gg_model.pth"
        model1.load_state_dict(torch.load("gg_model.pth"))
    summary(model=model1, input_size=(args.batch_size, 1, 489, 512), device="cuda")
    # model1.load_state_dict(torch.load('model.pth'))

    # 创建模型2、优化器和损失函数
    model2 = create_model(num_classes=args.num_classes, has_logits=False)
    if args.weights != "":
        assert os.path.exists(args.weights), "weights file: '{}' not exist.".format(args.weights)
        weights_dict = torch.load(args.weights)
        # 删除不需要的权重
        del_keys = ['head.weight', 'head.bias'] if model2.has_logits \
            else ['pre_logits.fc.weight', 'pre_logits.fc.bias', 'head.weight', 'head.bias']
        for k in del_keys:
            del weights_dict[k]
        print(model2.load_state_dict(weights_dict))

    if args.freeze_layers:
        for name, para in model2.named_parameters():
            # 除head, pre_logits外，其他权重全部冻结
            if "head" not in name and "pre_logits" not in name:
                para.requires_grad_(False)
            else:
                print("training {}".format(name))

    # pg = [p for p in model2.parameters() if p.requires_grad]
    # optimizer = optim.SGD(pg, lr=args.lr, momentum=0.9, weight_decay=5E-5)
    # lf = lambda x: ((1 + math.cos(x * math.pi / args.epochs)) / 2) * (1 - args.lrf) + args.lrf  # cosine
    # scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)

    summary(model=model2, input_size=(args.batch_size, 1, 645, 512), device="cuda")

    # 创建模型, 并将其移动到local_rank对应的GPU上
    # model = model.to(local_rank)
    optimizer1 = torch.optim.AdamW(model1.parameters(), lr=0.001, eps=1e-08)
    optimizer2 = torch.optim.AdamW(model2.parameters(), lr=0.001, eps=1e-08)
    total_steps = len(train_dataloader) * args.max_epochs  # 训练的总步数=训练集的大小*迭代轮数
    warm_up_ratio = 0.2
    scheduler = get_linear_schedule_with_warmup(  # 定义一个线性调度器
        optimizer1,
        num_warmup_steps=total_steps * warm_up_ratio,  # 学习率逐渐增加的步数，在这些步数内，学习率将从初始值逐渐增加到设定的最大值
        num_training_steps=total_steps  # 表示总的训练步数
    )
    # model.load_state_dict(torch.load('model_weights.pth'))
    criterion = nn.CrossEntropyLoss()
    model = [model1, model2]
    trainer = Trainer(model1=model1, model2=model2, optimizer1=optimizer1, optimizer2=optimizer2, scheduler=scheduler,
                      train_dataloader=train_dataloader,
                      val_data_loader=val_data_loaderaloader, device=args.device, batch_size=args.batch_size)
    trainer.train(args.max_epochs)
    #
    # destroy_process_group()
    # for epoch in range(10):
    #     train_loss = train(model, train_dataloader, optimizer, criterion)
    #     print(f'Epoch {epoch + 1}/{10}, Train Loss: {train_loss:.4f}')

    # 加载预训练的权重（可选）
    # model.load_state_dict(torch.load('model_weights.pth'))
    # 训练模型
    # for epoch in range(10):
    #     train_loss = train(model, train_dataloader, optimizer, loss_fn, local_rank)
    #     # test_loss, test_accuracy = do_test(model, train_dataloader, criterion)
    #     print(
    #         f"Epoch {epoch + 1} - Training Loss: {train_loss:.4f}")
    # print(
    #     f"Epoch {epoch + 1} - Training Loss: {train_loss:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='MCNN distributed training job')
    parser.add_argument('--seed', type=int, default=1)
    parser.add_argument('--nproc_per_node', type=int, default=1)
    parser.add_argument('--nnode', type=int, default=1)
    parser.add_argument('--node_rank', type=int, default=1)
    parser.add_argument('--batch_size', type=int, default=1, help='Input batch size on each device (default: 32)')
    parser.add_argument('--max_epochs', type=int, default=10)
    parser.add_argument('--val_rate', type=int, default=0.2)
    parser.add_argument('--num_classes', type=int, default=9)
    parser.add_argument('--continue_train', type=bool, default=False)
    parser.add_argument('--lr', type=float, default=0.001)
    parser.add_argument('--lrf', type=float, default=0.01)

    # 数据集所在根目录

    parser.add_argument('--root_dir', type=str,
                        default="BIG_img/width")
    parser.add_argument('--label_dir', type=str,
                        default="BIG_image_dimensions_label.csv")
    parser.add_argument('--model-name', default='', help='create model name')

    # 预训练权重路径，如果不想载入就设置为空字符    ./vit_malware.pth'
    parser.add_argument('--weights', type=str, default='',
                        help='initial weights path')
    # 是否冻结权重
    parser.add_argument('--freeze-layers', type=bool, default=False)
    device = []
    # 检查CUDA是否可用
    if torch.cuda.is_available():
        # 获取可用的CUDA设备数量
        num_cuda_devices = torch.cuda.device_count()
        print("可用的CUDA设备:")
        for i in range(num_cuda_devices):
            device_name = f'cuda:{i}'
            print(device_name)
            device.append(device_name)
    else:
        print("CUDA不可用")
    parser.add_argument('--device', default=device, help='device id (i.e. 0 or 0,1 or cpu)')

    args = parser.parse_args()
    main(args)
